{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "better-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import det\n",
    "from numpy.linalg import eig\n",
    "from numpy.linalg import cholesky\n",
    "from scipy import optimize\n",
    "import progressbar\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-weekend",
   "metadata": {},
   "source": [
    "# Read data and initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "completed-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"./macrometrics_codes/data_m_ready.xlsx\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "protecting-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters \n",
    "nonlinear = \"yes\"\n",
    "logistic = \"yes\"\n",
    "interacted = \"no\"\n",
    "statevar = \"FFRshadow\"\n",
    "gamma = 10\n",
    "cq = 13\n",
    "lags = 6\n",
    "h = 48\n",
    "c_case = 2\n",
    "var_list = [\"GDPgap\",'CoreCPIGr12','FFRshadow']\n",
    "exog_vars = []\n",
    "n = len(var_list)\n",
    "ident = \"chol\"\n",
    "shockpos = 3 #position of the shock in the cholesky ordering\n",
    "shocksize = 1 #0=one standard deviation, all else: absolute values\n",
    "nboot = 100 #bootstraps\n",
    "alpha = 10 #90% confidence-interval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "automated-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter dictionary \n",
    "params = {\"non_linear\":nonlinear\n",
    "        ,\"logistic\":logistic\n",
    "         ,\"interacted\":interacted\n",
    "         ,\"statevar\":statevar\n",
    "         ,\"gamma\":gamma\n",
    "         ,\"cq\":cq\n",
    "         ,\"varlist\":var_list\n",
    "        ,\"lags\":lags\n",
    "        ,\"h\":h\n",
    "        ,\"c_case\":c_case\n",
    "        ,\"exog_vars\":exog_vars\n",
    "        ,\"num_vars\":n\n",
    "        ,\"identification\":ident\n",
    "        ,\"shockposition\":shockpos\n",
    "        ,\"shocksize\":shocksize\n",
    "        ,\"nboot\":nboot\n",
    "        ,\"CI\":alpha}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "normal-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "df = df.replace(\"NaN\",np.NaN) \\\n",
    "       .rename(columns={10:\"GDPgap\",18:'FFRshadow',22:'CoreCPIGr12'}) \\\n",
    "\n",
    "time = pd.date_range('1967-01-01', periods = df.shape[0], freq='1M')\n",
    "df[\"time\"] = time\n",
    "# select endogenous vars\n",
    "y = df[params[\"varlist\"]]\n",
    "\n",
    "# select exogenous vars\n",
    "exog = df[params[\"exog_vars\"]].add_suffix(\"_exog\")\n",
    "\n",
    "# select state (if nescesarry)\n",
    "if params[\"non_linear\"] == \"yes\" and params[\"logistic\"] == \"yes\":\n",
    "    s = df[params[\"statevar\"]].rename(\"state\")\n",
    "\n",
    "data = pd.concat([y,exog,s,df[\"time\"]],axis=1)\n",
    "\n",
    "# ignore NaN \n",
    "data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "# drop data before 2019\n",
    "data = data[data.time.dt.year<2019].reset_index(drop=True)\n",
    "\n",
    "# logistic transformation of state-variable\n",
    "if params[\"non_linear\"] == \"yes\" and params[\"logistic\"] == \"yes\":\n",
    "    data.state = (data.state - np.percentile(data.state,params[\"cq\"],interpolation='midpoint')) / np.std(data.state)\n",
    "    data[\"Fstate\"] = np.exp(-params[\"gamma\"]*data.state) / (1+np.exp(-params[\"gamma\"]*data.state))\n",
    "    \n",
    "    # state dummy\n",
    "    absval = np.percentile(data.state,params[\"cq\"],interpolation='midpoint')\n",
    "    data[\"state_dummy\"] =[1 if s <= absval else 0 for s in data.state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acknowledged-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df,params):\n",
    "    \"\"\"Prepare the data in accordance with specified\"\"\"\n",
    "    # Prep\n",
    "    s = df[\"state\"]\n",
    "    s = s.shift(1) # lagged one period \n",
    "    \n",
    "    # y matrix\n",
    "    y = df[params[\"varlist\"]]\n",
    "    \n",
    "    # Generate lags\n",
    "    lagged_vars = []\n",
    "    \n",
    "    for i in range(1,params[\"lags\"]+1):\n",
    "        lagged_vars.append(y.shift(i))\n",
    "        \n",
    "    # concat lagged vars and truncate    \n",
    "    lagged_vars = pd.concat(lagged_vars,axis=1).dropna()\n",
    "    \n",
    "    # truncate other dataframes\n",
    "    y = df[params[\"varlist\"]][params[\"lags\"]:]\n",
    "    state = s[params[\"lags\"]:].values.reshape(-1,1)\n",
    "    T = len(y)\n",
    "    \n",
    "    # add constant and/or trend to X matrix\n",
    "    if c_case == 0:\n",
    "        c = np.NaN\n",
    "    elif c_case == 1:\n",
    "        c = np.ones(lagged_vars.shape[0])\n",
    "    elif c_case == 2:\n",
    "        list(zip(np.ones(lagged_vars.shape[0]),lagged_vars.index-lags))\n",
    "    else:\n",
    "        print('c_case variable needs to be set to 0, 1, or 2.')\n",
    "        \n",
    "    \n",
    "    # add exogenous variables\n",
    "    if params[\"exog_vars\"]:\n",
    "        exog = []\n",
    "        for i in range(1,params[\"lags\"]+1):\n",
    "            Xex.append(params[\"exog_vars\"].shift(i))\n",
    "    else:\n",
    "        exog = []\n",
    "        print(\"No exogenous variables defined\")\n",
    "    \n",
    "    return state,y,lagged_vars,T,exog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "described-familiar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No exogenous variables defined\n"
     ]
    }
   ],
   "source": [
    "state,y,lagged_vars,T,exog = prepare_data(data,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "involved-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_criteria(omega,U,A):\n",
    "    \"\"\" Returns the AIC and BIC lag selection criteria\"\"\"\n",
    "    AIC = np.log(det(omega)) + 2/len(U)*len(A)\n",
    "    BIC = np.log(det(omega)) + np.log(len(U))/len(U)*len(A)\n",
    "    return AIC, BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pleased-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_A_U_omega(lagged_vars,state,y,exog):\n",
    "    ## Linear and nonlinear var for initial values\n",
    "    rX = lagged_vars.shape[0]\n",
    "    cX = lagged_vars.shape[1]\n",
    "    et = np.ones((1,cX)) #vector of ones\n",
    "    \n",
    "    ## NONLINEAR\n",
    "    \n",
    "    # Check for exogenous variables\n",
    "    if exog:\n",
    "        Xm = np.block([lagged_vars, lagged_vars * np.kron(state,et), lagged_vars * np.kron(state**2*np.sign(state),et),np.ones((rX,1)),exog])\n",
    "    else:\n",
    "        Xm = np.block([lagged_vars, lagged_vars * np.kron(state,et), lagged_vars * np.kron(state**2*np.sign(state),et),np.ones((rX,1))])\n",
    "        \n",
    "    A = inv(np.dot(Xm.T,Xm))@(np.dot(Xm.T,y))\n",
    "    U = y - Xm @ A\n",
    "    omega = np.cov(U.T)\n",
    "    \n",
    "    # Lag selection criteria\n",
    "    AIC, BIC = lag_criteria(omega,U,A)\n",
    "    \n",
    "    ## LINEAR BENCHMARK\n",
    "    if exog:\n",
    "        Xm_lin = np.block([lagged_vars,np.ones((rX,1)),exog])\n",
    "    else:\n",
    "        Xm_lin = np.block([lagged_vars,np.ones((rX,1))])\n",
    "        \n",
    "    A_lin = inv(np.dot(Xm_lin.T,Xm_lin))@(np.dot(Xm_lin.T,y))\n",
    "    U_lin = y - Xm_lin @ A_lin\n",
    "    omega_lin = np.cov(U_lin.T)\n",
    "    A_lin = A_lin[:-1] #potentiel fejl\n",
    "    \n",
    "    return omega,U,A,omega_lin,U_lin,A_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "piano-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "omega,U,A,omega_lin,U_lin,A_lin = find_A_U_omega(lagged_vars,state,y,exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sharing-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lag_criteria(omega,U,A,omega_lin,U_lin,A_lin):\n",
    "    \"\"\" Returns AIC and BIC lag selection criteria\"\"\"\n",
    "    #non-linear model\n",
    "    AIC, BIC = lag_criteria(omega,U,A)\n",
    "\n",
    "    #linear benchmark modeel\n",
    "    AIC_lin, BIC_lin = lag_criteria(omega_lin,U_lin,A_lin)\n",
    "    print(\"--------\")\n",
    "    print(\"Lag selection criteria:\")\n",
    "    print(\"--------\")\n",
    "    print(\"Nonlinear model:\")\n",
    "    print(f\"AIC = {AIC:.5f}\")\n",
    "    print(f\"BIC = {BIC:.5f}\")\n",
    "    print(\"--------\")\n",
    "    print(\"Linear model:\")\n",
    "    print(f\"AIC = {AIC_lin:.5f}\")\n",
    "    print(f\"BIC = {BIC_lin:.5f}\")\n",
    "    print(\"--------\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "consecutive-hypothetical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Lag selection criteria:\n",
      "--------\n",
      "Nonlinear model:\n",
      "AIC = -7.37621\n",
      "BIC = -6.97625\n",
      "--------\n",
      "Linear model:\n",
      "AIC = -6.44517\n",
      "BIC = -6.31428\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "find_lag_criteria(omega,U,A,omega_lin,U_lin,A_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "nervous-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0 = -params[\"gamma\"]\n",
    "scale_penalty = 1e6\n",
    "scale_penalty_beta = 0\n",
    "lambda_prior = 1\n",
    "theta_prior = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "executed-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_prior = {\"theta0\":theta0\n",
    "          ,\"scale_penalty\":scale_penalty\n",
    "          ,\"scale_penalty_beta\":scale_penalty_beta\n",
    "          ,\"lambda_prior\":lambda_prior\n",
    "          ,\"theta_prior\":theta_prior}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "collectible-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minnesota_prior(params,omega_lin,s_prior):\n",
    "    \"\"\"\n",
    "    shrinkage prior for autoregressive parameters in vector autoregressive (VAR) models\n",
    "    \n",
    "    Args:\n",
    "    params(dict):\n",
    "    num_vars = # of variables in the VAR\n",
    "    lags = # of lags in the VAR\n",
    "    \n",
    "    s_prior(dict):\n",
    "    - lambda_prior = controls cross-variable responses (smaller values mean stronger prior \n",
    "    - theta_prior = controls own response of variables\n",
    "    \n",
    "    Omega_lin = covariance matrix of residuals to make restrictions scale\n",
    "    invariant (typically from \"first stage\" unrestricted VAR). (estimated in find_lag_criteria)\n",
    "    \n",
    "    Returns:\n",
    "    matrix of tighness for restrictions\n",
    "    \"\"\"\n",
    "    prior_mean = np.zeros((params[\"num_vars\"],params[\"num_vars\"]*params[\"lags\"]))\n",
    "\n",
    "    for i in range(params[\"num_vars\"]):\n",
    "        prior_mean[i,i]=1\n",
    "    \n",
    "    \n",
    "    prior_var = np.zeros((params[\"num_vars\"],params[\"num_vars\"]*params[\"lags\"]))\n",
    "\n",
    "    for lag in range(params[\"lags\"]):\n",
    "        for i in range(params[\"num_vars\"]):\n",
    "            for j in range(params[\"num_vars\"]):\n",
    "                if i == j:\n",
    "                    prior_var[i,j+lag*params[\"num_vars\"]] = s_prior[\"lambda_prior\"]**2 / ((lag+1)**2)\n",
    "                else:\n",
    "                    prior_var[i,j+lag*params[\"num_vars\"]] = (s_prior[\"lambda_prior\"]*s_prior[\"theta_prior\"])**2 / ((lag+1)**2) * (omega_lin[i,i]/omega_lin[j,j])\n",
    "\n",
    "    return prior_mean, prior_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "worst-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_mean, prior_var = minnesota_prior(params,omega_lin,s_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "stable-raising",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_prior[\"prior_mean\"] = prior_mean\n",
    "s_prior[\"prior_var\"] = prior_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "posted-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTVAR_mleScov(resids,state,omega_1,omega_2,theta,T,num_var):\n",
    "    \"\"\" \n",
    "    this function computes the likelihood for the process the VAR with a smooth transtion (observed) state \n",
    "    Transition for state is given by two functions:\n",
    "    \n",
    "    slopes/intercept     = F(Z) = exp(gamma*Z)/(1+exp(gamma*Z))\n",
    "    cov matrix of shocks = M(Z) = exp(theta*Z)/(1+exp(theta*Z))\n",
    "    \n",
    "    identifying assuumtpions are that gamma<0, theta<0\n",
    "    \n",
    "    compute VAR coefficients using GLS\n",
    "    \n",
    "    Args:\n",
    "    resids = residuals from find_lag_criteria (u-vector)\n",
    "    s = regime shifter for contemporanous response (matrices OMEGA)\n",
    "    omega_1 = cov matrix of residuals in regime 0\n",
    "    omega_2 = cov matrix of residuals in regime 1\n",
    "    theta = transition speed for coevariance matrix of VAR residuals\n",
    "    T = sample size\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # weights on the \"expansion\" regime\n",
    "    M_Z_t = np.exp(theta * state) / (1 + np.exp(theta * state))\n",
    "    \n",
    "    logL = 0 \n",
    "    \n",
    "    for i in range(0,T):\n",
    "        #compute time-varying parameters\n",
    "        omega_t = omega_1 * (1 - M_Z_t[i]) + omega_2 * M_Z_t[i]\n",
    "        \n",
    "        e_t = resids.values[i]\n",
    "        \n",
    "        logL = logL - 0.5*(np.log(det(omega_t)) + e_t @ inv(omega_t) @ e_t.T)\n",
    "\n",
    "    return logL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eligible-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dupmat(n):\n",
    "    \"\"\"Returns Magnus and Neudecker's duplication matrix of size n\"\"\"\n",
    "    \n",
    "    a = np.tril(np.ones(n))\n",
    "    i = np.where(a>0)\n",
    "    a[i] = range(0,len(i[0]))\n",
    "    a = a + np.tril(a,-1).T\n",
    "    \n",
    "    # create vector\n",
    "    j = a.flatten(\"F\")\n",
    "    \n",
    "    m = n*(n+1)/2;\n",
    "    d = np.zeros((n*n,int(m)));\n",
    "    \n",
    "    for r in range(d.shape[0]):\n",
    "        d[r,int(j[r])] = 1\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "medical-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_mat_n = dupmat(params[\"num_vars\"])\n",
    "d_plus = inv(np.dot(dup_mat_n.T,dup_mat_n))@dup_mat_n.T\n",
    "omegalin_var = 2*d_plus@np.kron(omega_lin,omega_lin)@d_plus.T / T\n",
    "s_prior[\"omega_var\"] = s_prior[\"scale_penalty\"]*np.ones(np.diag(omegalin_var).shape[0])\n",
    "s_prior[\"omega_lin\"] = omega_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "proof-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a small departure for one of the regimes to make sure that starting\n",
    "#values are slightly different\n",
    "D=np.random.randn(len(omega),len(omega))\n",
    "#omega_1 = omega\n",
    "#omega_2 = omega + min(eig(omega)[0]) * D @ D.T\n",
    "omega_1 = np.array([[0.1522,1.2358e-04,0.0122],[1.2358e-04,0.0311,0.0037],[0.0122,0.0037,0.1115]])\n",
    "omega_2 = np.array([[0.1637,-0.0345,0.0431],[-0.0345,0.3561,-0.0826],[0.0431,-0.0826,0.2093]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "basic-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Cholesky decomposition since we need to look only for a lower\n",
    "#trinagular matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "robust-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = cholesky(omega_1)\n",
    "s2 = cholesky(omega_2)\n",
    "s2 = s2.flatten(\"F\")\n",
    "omega_length_cov = len(s2[s2!=0])\n",
    "s_desc = {\"omega_length\":omega_length_cov,\"T\":T}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "quick-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "param0 = np.block([s2[s2!=0],s2[s2!=0],s_prior[\"theta0\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "separated-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unvech(vec):\n",
    "    \"\"\" creates a matrix from a vectorc \"\"\"\n",
    "    rows = .5 * (-1 + np.sqrt(1 + 8 * len(vec)))\n",
    "    rows = int(np.round(rows))\n",
    "\n",
    "    result = np.zeros((rows, rows))\n",
    "    counter1 = 0 \n",
    "    for row in range(rows):\n",
    "        for i in range(row,rows):\n",
    "            result[i,row] = vec[counter1]\n",
    "            counter1 +=1\n",
    "\n",
    "    for row in range(rows):\n",
    "        for i in range(row,rows):\n",
    "            result[row,i] = result[i,row]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "technical-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec2matScov(X):\n",
    "    \"\"\" convert vector of parameters into approapriate matrices \n",
    "    \n",
    "    Args:\n",
    "    param0: Vector of parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # the curvature in the transition function\n",
    "    theta = X[-1]\n",
    "    \n",
    "    #  covariance matrix of the error terms\n",
    "    ## pick vectorized matrices from the vector of parameters, param0\n",
    "    omega_1 = X[:s_desc[\"omega_length\"]]\n",
    "    omega_2 = X[s_desc[\"omega_length\"]:-1]\n",
    "    \n",
    "    # unvectorize matrices\n",
    "    omega_1_m = unvech(omega_1)\n",
    "    omega_2_m = unvech(omega_2)\n",
    "    \n",
    "    # Remove elements above diagonal\n",
    "    omega_1_m = omega_1_m - np.triu(omega_1_m,1)\n",
    "    omega_2_m = omega_2_m - np.triu(omega_2_m,1)\n",
    "    \n",
    "    # Ensure the covariance matrices are positive definite (this step is effectively using the nature of the Cholesky decomposition)\n",
    "    omega_1 = omega_1_m @ omega_1_m.T\n",
    "    omega_2 = omega_2_m @ omega_2_m.T\n",
    "    \n",
    "    return omega_1, omega_2,theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "enormous-rating",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_LSTVAR_mleScov(X,resids,state,s_desc,params,s_prior):\n",
    "   \n",
    "    omega_1, omega_2, theta = vec2matScov(X)\n",
    "    \n",
    "    if theta<0:\n",
    "        if np.min(eig(omega_1)[0])>0 and np.min(eig(omega_2)[0])>0:\n",
    "            obj_logl = LSTVAR_mleScov(resids,state,omega_1,omega_2,theta,s_desc[\"T\"],params[\"num_vars\"])\n",
    "            \n",
    "            #take the negative of the log-likelihood (because the objective\n",
    "            #function is minimization rather than maximization) and add\n",
    "            #penalty for deviation of theta (the curvature in the transition\n",
    "            #probability) from the prior.  % take the negative of the log-likelihood (because the objective\n",
    "            #function is minimization rather than maximization) and add\n",
    "            #penalty for deviation of theta (the curvature in the transition\n",
    "            #probability) from the prior. \n",
    "            \n",
    "            obj_logl = -obj_logl + (theta-s_prior[\"theta0\"])**2 * s_prior[\"scale_penalty\"]\n",
    "        else:\n",
    "            obj_logl = 1e12\n",
    "    else:\n",
    "        obj_logl = 1e12\n",
    "\n",
    "    return obj_logl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "reasonable-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "resids = U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "guilty-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = optimize.minimize(max_LSTVAR_mleScov,param0,args=(resids,state,s_desc,params,s_prior), method = 'Nelder-Mead',options={'maxiter':1000,'maxfev':1000,'xatol':1e-6,'fatol':1e-6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "impaired-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack results\n",
    "omega_1, omega_2, theta = vec2matScov(param0)\n",
    "omega_1_opt, omega_2_opt, gamma_opt = vec2matScov(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "natural-creek",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log-likelihood: -1311.8577672497593\n",
      "------\n",
      "Values before optimization\n",
      "omega_1: [[0.16369999999999998, -0.0345, 0.0431], [-0.0345, 0.3561000000000001, -0.0826], [0.0431, -0.0826, 0.2093]]\n",
      "omega_2: [[0.16369999999999998, -0.0345, 0.0431], [-0.0345, 0.3561000000000001, -0.0826], [0.0431, -0.0826, 0.2093]]\n",
      "theta: -10.0\n",
      "------\n",
      "Values after optimization\n",
      "omega_1: [[0.1444419801180465, -0.009410119804626173, 0.01782977023357277], [-0.009410119804626173, 0.043501824856164543, -0.036286624916261626], [0.01782977023357277, -0.036286624916261626, 0.19913780590079985]]\n",
      "omega_2: [[0.5370169307598047, -0.08558955205462175, 0.10457335845479447], [-0.08558955205462175, 0.03412744757238577, -0.04288415803279071], [0.10457335845479447, -0.04288415803279071, 0.1016452172713204]]\n",
      "theta: -9.999647599595\n"
     ]
    }
   ],
   "source": [
    "print(f\"log-likelihood: {res.fun}\")\n",
    "print(\"------\")\n",
    "print(\"Values before optimization\")\n",
    "print(f\"omega_1: {omega_1.tolist()}\")\n",
    "print(f\"omega_2: {omega_2.tolist()}\")\n",
    "print(f\"theta: {theta}\")\n",
    "print(\"------\")\n",
    "print(\"Values after optimization\")\n",
    "print(f\"omega_1: {omega_1_opt.tolist()}\")\n",
    "print(f\"omega_2: {omega_2_opt.tolist()}\")\n",
    "print(f\"theta: {gamma_opt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "vulnerable-surprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cholesky\n",
    "s1 = cholesky(omega_1_opt)\n",
    "s1 = s1.flatten(\"F\")\n",
    "s2 = cholesky(omega_2_opt)\n",
    "s2 = s1.flatten(\"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ignored-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "param0_MCMC =  np.block([s1[s1!=0],s2[s2!=0],gamma])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-marshall",
   "metadata": {},
   "source": [
    "# Markov Chain Monte Carlo algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "english-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "rX = lagged_vars.shape[0]\n",
    "cX = lagged_vars.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "nasty-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unvec(A,n1,n2):\n",
    "    \"\"\" worker function to create matrix from vector \n",
    "    \n",
    "    Args:\n",
    "    A: input matrix\n",
    "    n1: dimension 1\n",
    "    n2: dimension 2\n",
    "    \n",
    "    Returns:\n",
    "    v: matrix of dimension n1xn2\n",
    "    \"\"\"\n",
    "    \n",
    "    v = np.empty((n1,n2))\n",
    "    for i in range(0,n2):\n",
    "        v[:,i] = A[i*n1:(i+1)*n1]\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "physical-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTVAR_struct(theta,gamma,state,lagged_vars,y,exog,omega_1,omega_2,T,c_case,lags,nvar,n_periods):\n",
    "    \"\"\" \n",
    "    this function computes the likelihood for the process the VAR with a smooth transtion (observed) state \n",
    "    Transition for state is given by two functions:\n",
    "    \n",
    "    slopes/intercept     = F(Z) = exp(gamma*Z)/(1+exp(gamma*Z))\n",
    "    cov matrix of shocks = M(Z) = exp(theta*Z)/(1+exp(theta*Z))\n",
    "    \n",
    "    identifying assuumtpions are that gamma<0, theta<0\n",
    "    \n",
    "    compute VAR coefficients using GLS\n",
    "    \n",
    "    Args:\n",
    "    theta: transition speed for coevariance matrix of VAR residuals\n",
    "    gamma: transition speed for VAR coefs\n",
    "    s: regime shifter for contemporanous response (matrices OMEGA)\n",
    "    lagged_vars: vector of lagged variables\n",
    "    y: vector of dependent variables\n",
    "    exog: vector of exogenous variables\n",
    "    omega_1: cov matrix of residuals in regime 0\n",
    "    omega_2: cov matrix of residuals in regime 1\n",
    "    T: sample size\n",
    "    c_case: controls trend, regime-specific intercept and regime-specific trend.\n",
    "    lags: no. lags\n",
    "    nvar: number of variables in the VAR\n",
    "    n_periods = number of forecasted periods\n",
    "    \"\"\"\n",
    "    if c_case == 0:\n",
    "        trendON = 0 #0 = trend, 1 = no trend\n",
    "        inter_regspec = 0 #1=regime-specific intercept\n",
    "        trend_regspec = 0 #1= regime-specific trend\n",
    "    elif c_case == 1:\n",
    "        trendON = 0\n",
    "        inter_regspec = 1\n",
    "        trend_regspec = 0;\n",
    "    elif c_case == 2:\n",
    "        trendON = 1\n",
    "        inter_regspec = 1\n",
    "        trend_regspec = 1\n",
    "    \n",
    "    # weights on the \"expansion\" regime\n",
    "    M_Z_t = np.exp(theta * state) / (1 + np.exp(theta * state))\n",
    "    F_Z_t = np.exp(gamma * state) / (1 + np.exp(gamma * state))\n",
    "    \n",
    "    # construct vector of regressors\n",
    "    # the last two entries capture constant terms and trends\n",
    "    rX = lagged_vars.shape[0]\n",
    "    cX = lagged_vars.shape[1]\n",
    "    \n",
    "    if trendON == 0:\n",
    "        if inter_regspec == 0: \n",
    "            if parameters[\"lags\"] > 0:\n",
    "                if exog:\n",
    "                    Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), np.ones((len(F_Z_t),1)),exog])\n",
    "                else:\n",
    "                    Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), np.ones((len(F_Z_t),1))])\n",
    "            else: \n",
    "                Xm = np.ones((len(F_Z_t),1))\n",
    "        else:\n",
    "            if exog:\n",
    "                Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), (1-F_Z_t), F_Z_t, exog])\n",
    "            else:\n",
    "                Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), (1-F_Z_t), F_Z_t])\n",
    "    \n",
    "    else: \n",
    "        if inter_regspec == 0 and trend_regspec == 0:\n",
    "            if exog:\n",
    "                Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), np.ones((len(F_Z_t),1)),np.array(range(len(F_Z_t))).reshape(-1,1), exog])\n",
    "            else:\n",
    "                Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), np.ones((len(F_Z_t),1)),np.array(range(len(F_Z_t))).reshape(-1,1)])\n",
    "                \n",
    "        elif inter_regspec == 1 and trend_regspec == 0: \n",
    "            if exog:\n",
    "                Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), (1-F_Z_t), F_Z_t, np.array(range(len(F_Z_t))).reshape(-1,1), exog])\n",
    "            else:\n",
    "                Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), (1-F_Z_t), F_Z_t, np.array(range(len(F_Z_t))).reshape(-1,1)])\n",
    "        \n",
    "        elif inter_regspec == 0 and trend_regspec == 1: \n",
    "            if exog:\n",
    "                Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), np.ones((len(F_Z_t),1)),(1-F_Z_t) * np.array(range(len(F_Z_t))).reshape(-1,1), F_Z_t * np.array(range(len(F_Z_t))).reshape(-1,1), exog])\n",
    "            else:\n",
    "                Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), np.ones((len(F_Z_t),1)),(1-F_Z_t) * np.array(range(len(F_Z_t))).reshape(-1,1), F_Z_t * np.array(range(len(F_Z_t))).reshape(-1,1)])\n",
    "        \n",
    "        elif inter_regspec == 1 and trend_regspec == 1: \n",
    "            if exog:\n",
    "                Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), (1-F_Z_t), F_Z_t, (1-F_Z_t) * np.array(range(len(F_Z_t))).reshape(-1,1), F_Z_t * np.array(range(len(F_Z_t))).reshape(-1,1), exog])\n",
    "            else:\n",
    "                Xm = np.block([lagged_vars.values * np.tile(1 - F_Z_t,(1,cX)), lagged_vars.values * np.tile(F_Z_t,(1,cX)), (1-F_Z_t), F_Z_t, (1-F_Z_t) * np.array(range(len(F_Z_t))).reshape(-1,1), F_Z_t * np.array(range(len(F_Z_t))).reshape(-1,1)])\n",
    "    \n",
    "    # Estimate VAR coefficients using GLS\n",
    "    num0 = 0\n",
    "    den0 = 0\n",
    "    \n",
    "    for t in range(0,T):\n",
    "        wgt_m = inv(omega_1 * (1 - M_Z_t[t]) + omega_2 * M_Z_t[t])\n",
    "        num0_mat = Xm[t:].T @ y[t:].values @ wgt_m\n",
    "        \n",
    "        num0 = num0 + num0_mat.flatten(\"F\")\n",
    "        den0 = den0 + np.kron(wgt_m, Xm[t:].T @ Xm[t:])\n",
    "        \n",
    "    betaK = inv(den0) @ num0\n",
    "    betaK1 = unvec(betaK,cX*2+trendON*(1+trend_regspec)+1+inter_regspec+n_periods, nvar)\n",
    "    \n",
    "    # VAR coefficients in regime 0\n",
    "    beta0 = betaK1[:cX,:].T\n",
    "    # VAR coefficients in regime 1\n",
    "    beta1 = betaK1[cX:2*cX,:].T\n",
    "    \n",
    "    # compute coefficients on the constant term and any other control variables\n",
    "    beta_const = betaK1[2*cX:2*cX+1,:].T\n",
    "    beta_other = betaK1[2*cX+2:,:]\n",
    "    \n",
    "    # compute residuals\n",
    "    residsM = y.values - Xm @ betaK1\n",
    "    \n",
    "    # compute log-likelihood\n",
    "    logL = 0\n",
    "    \n",
    "    for i in range(T):\n",
    "        # compute time-varying parameters\n",
    "        omega_t = omega_1 * (1 - M_Z_t[i]) + omega_2 * M_Z_t[i]\n",
    "        \n",
    "        e_t = residsM[i]\n",
    "        \n",
    "        logL = logL - 0.5*(np.log(det(omega_t)) + e_t@inv(omega_t)@e_t.T)\n",
    "    \n",
    "    return logL, beta0, beta1, beta_const, beta_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dimensional-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec2matSF_struct(X,state,lagged_vars,y,exog,T,c_case,lags,nvar,n_periods):\n",
    "    \"\"\" \n",
    "    this function computes the likelihood for the process the VAR with a smooth transtion (observed) state \n",
    "    Transition for state is given by two functions:\n",
    "    \n",
    "    slopes/intercept     = F(Z) = exp(gamma*Z)/(1+exp(gamma*Z))\n",
    "    cov matrix of shocks = M(Z) = exp(theta*Z)/(1+exp(theta*Z))\n",
    "    \n",
    "    identifying assuumtpions are that gamma<0, theta<0\n",
    "    \n",
    "    compute VAR coefficients using GLS\n",
    "    \n",
    "    Args:\n",
    "    theta: transition speed for coevariance matrix of VAR residuals\n",
    "    gamma: transition speed for VAR coefs\n",
    "    s: regime shifter for contemporanous response (matrices OMEGA)\n",
    "    lagged_vars: vector of lagged variables\n",
    "    y: vector of dependent variables\n",
    "    exog: vector of exogenous variables\n",
    "    omega_1: cov matrix of residuals in regime 0\n",
    "    omega_2: cov matrix of residuals in regime 1\n",
    "    T: sample size\n",
    "    c_case: controls trend, regime-specific intercept and regime-specific trend.\n",
    "    lags: no. lags\n",
    "    nvar: number of variables in the VAR\n",
    "    n_periods = number of forecasted periods\n",
    "    \"\"\"\n",
    "    omega_1, omega_2, theta = vec2matScov(X)\n",
    "    gamma = theta\n",
    "    \n",
    "    if c_case == 0:\n",
    "        trendON = 0 #0 = trend, 1 = no trend\n",
    "        inter_regspec = 0 #1=regime-specific intercept\n",
    "        trend_regspec = 0 #1= regime-specific trend\n",
    "    elif c_case == 1:\n",
    "        trendON = 0\n",
    "        inter_regspec = 1\n",
    "        trend_regspec = 0;\n",
    "    elif c_case == 2:\n",
    "        trendON = 1\n",
    "        inter_regspec = 1\n",
    "        trend_regspec = 1\n",
    "\n",
    "    # weights on the \"expansion\" regime\n",
    "    M_Z_t = np.exp(theta * state) / (1 + np.exp(theta * state))\n",
    "    F_Z_t = np.exp(gamma * state) / (1 + np.exp(gamma * state))\n",
    "    \n",
    "    # construct vector of regressors\n",
    "    # the last two entries capture constant terms and trends\n",
    "    rX = lagged_vars.shape[0]\n",
    "    cX = lagged_vars.shape[1]\n",
    "    \n",
    "    if trendON == 0:\n",
    "        if inter_regspec == 0: \n",
    "            if parameters[\"lags\"] > 0:\n",
    "                if exog:\n",
    "                    Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), np.ones((len(F_Z_t),1)),exog])\n",
    "                else:\n",
    "                    Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), np.ones((len(F_Z_t),1))])\n",
    "            else: \n",
    "                Xm = np.ones((len(F_Z_t),1))\n",
    "        else:\n",
    "            if exog:\n",
    "                Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), (1-F_Z_t), F_Z_t, exog])\n",
    "            else:\n",
    "                Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), (1-F_Z_t), F_Z_t])\n",
    "    \n",
    "    else: \n",
    "        if inter_regspec == 0 and trend_regspec == 0:\n",
    "            if exog:\n",
    "                Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), np.ones((len(F_Z_t),1)),np.array(range(len(F_Z_t))).reshape(-1,1), exog])\n",
    "            else:\n",
    "                Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), np.ones((len(F_Z_t),1)),np.array(range(len(F_Z_t))).reshape(-1,1)])\n",
    "                \n",
    "        elif inter_regspec == 1 and trend_regspec == 0: \n",
    "            if exog:\n",
    "                Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), (1-F_Z_t), F_Z_t, np.array(range(len(F_Z_t))).reshape(-1,1), exog])\n",
    "            else:\n",
    "                Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), (1-F_Z_t), F_Z_t, np.array(range(len(F_Z_t))).reshape(-1,1)])\n",
    "        \n",
    "        elif inter_regspec == 0 and trend_regspec == 1: \n",
    "            if exog:\n",
    "                Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), np.ones((len(F_Z_t),1)),(1-F_Z_t) * np.array(range(len(F_Z_t))).reshape(-1,1), F_Z_t * np.array(range(len(F_Z_t))).reshape(-1,1), exog])\n",
    "            else:\n",
    "                Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), np.ones((len(F_Z_t),1)),(1-F_Z_t) * np.array(range(len(F_Z_t))).reshape(-1,1), F_Z_t * np.array(range(len(F_Z_t))).reshape(-1,1)])\n",
    "        \n",
    "        elif inter_regspec == 1 and trend_regspec == 1: \n",
    "            if exog:\n",
    "                Xm = np.block([lagged_vars * np.tile(1-F_Z_t,(1,cX)), lagged_vars * np.tile(F_Z_t,(1,cX)), (1-F_Z_t), F_Z_t, (1-F_Z_t) * np.array(range(len(F_Z_t))).reshape(-1,1), F_Z_t * np.array(range(len(F_Z_t))).reshape(-1,1), exog])\n",
    "            else:\n",
    "                Xm = np.block([lagged_vars.values * np.tile(1 - F_Z_t,(1,cX)), lagged_vars.values * np.tile(F_Z_t,(1,cX)), (1-F_Z_t), F_Z_t, (1-F_Z_t) * np.array(range(len(F_Z_t))).reshape(-1,1), F_Z_t * np.array(range(len(F_Z_t))).reshape(-1,1)])\n",
    "    \n",
    "    # Estimate VAR coefficients using GLS\n",
    "    num0 = 0\n",
    "    den0 = 0\n",
    "    \n",
    "    for t in range(0,T):\n",
    "        wgt_m = inv(omega_1 * (1 - M_Z_t[t]) + omega_2 * M_Z_t[t])\n",
    "        num0_mat = Xm[t:].T @ y[t:].values @ wgt_m\n",
    "        \n",
    "        num0 = num0 + num0_mat.flatten(\"F\")\n",
    "        den0 = den0 + np.kron(wgt_m, Xm[t:].T @ Xm[t:])\n",
    "        \n",
    "    betaK = inv(den0) @ num0\n",
    "    betaK1 = unvec(betaK,cX*2+trendON*(1+trend_regspec)+1+inter_regspec+n_periods, nvar)\n",
    "    \n",
    "    # VAR coefficients in regime 0\n",
    "    beta0 = betaK1[:cX,:].T\n",
    "    # VAR coefficients in regime 1\n",
    "    beta1 = betaK1[cX:2*cX,:].T\n",
    "    \n",
    "    # compute coefficients on the constant term and any other control variables\n",
    "    beta_const = betaK1[2*cX:2*cX+1,:].T\n",
    "    beta_other = betaK1[2*cX+2:,:]\n",
    "    \n",
    "    # compute residuals\n",
    "    residsM = y.values - Xm @ betaK1\n",
    "    \n",
    "    # compute log-likelihood\n",
    "    logL = 0\n",
    "    \n",
    "    for i in range(T):\n",
    "        # compute time-varying parameters\n",
    "        omega_t = omega_1 * (1 - M_Z_t[i]) + omega_2 * M_Z_t[i]\n",
    "        \n",
    "        e_t = residsM[i]\n",
    "        \n",
    "        logL = logL - 0.5*(np.log(det(omega_t)) + e_t@inv(omega_t)@e_t.T)\n",
    "    \n",
    "    return logL, beta0, beta1, beta_const, beta_other, omega_1,omega_2,theta,gamma,residsM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "innocent-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_LSTVAR_mleS_struct(X,state,lagged_vars,y,exog,T,params):\n",
    "    \n",
    "    omega_1, omega_2, theta = vec2matScov(X)\n",
    "    \n",
    "    if theta<0:\n",
    "        if np.min(eig(omega_1)[0])>0 and np.min(eig(omega_2)[0])>0:\n",
    "            gamma = theta\n",
    "            n_periods = np.array(exog).shape[0]\n",
    "            obj_logL, beta0, beta1, beta_const, beta_other  = LSTVAR_struct(theta,gamma,state,lagged_vars,y,exog,omega_1,omega_2,s_desc[\"T\"],params[\"c_case\"],params[\"lags\"],params[\"num_vars\"],n_periods)\n",
    "            \n",
    "            # restriction of the speed of change in the regime\n",
    "            penalty_term0 = (theta - s_prior[\"theta0\"])**2 * s_prior[\"scale_penalty\"]\n",
    "            \n",
    "            if params[\"lags\"]>0:\n",
    "                penalty_term1 = 0.5 * sum(sum((beta1 - s_prior[\"prior_mean\"])**2 / s_prior[\"prior_var\"]))\n",
    "                penalty_term2 = 0.5 * sum(sum((beta0 - s_prior[\"prior_mean\"])**2 / s_prior[\"prior_var\"]))\n",
    "            else:\n",
    "                penalty_term1 = 0\n",
    "                penalty_term2 = 0\n",
    "                \n",
    "            # bayesian restriction: VAR covariance matrix of residuals\n",
    "            m1 = np.tril(omega_1 - s_prior[\"omega_lin\"])\n",
    "            m2 = np.tril(omega_2 - s_prior[\"omega_lin\"])\n",
    "            \n",
    "            penalty_term3 = 0.5 * np.sum(np.sum(m1[m1!=0].flatten(\"F\")**2 / s_prior[\"omega_var\"]))\n",
    "            penalty_term4 = 0.5 * np.sum(np.sum(m2[m2!=0].flatten(\"F\")**2 / s_prior[\"omega_var\"]))\n",
    "            \n",
    "            obj_logL = -obj_logL + penalty_term0 + penalty_term1 + penalty_term2 + penalty_term3 + penalty_term4\n",
    "            \n",
    "        else:\n",
    "             obj_logL = 1e12\n",
    "    else:\n",
    "        obj_logL = 1e12\n",
    "    \n",
    "    return obj_logL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "given-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_logLoptimizeMCMC_struct(X,draws,params):\n",
    "    print('Markov chain Monte Carlo...')\n",
    "    # initial value and the fit\n",
    "    J1 = max_LSTVAR_mleS_struct(X,state,lagged_vars,y,exog,T,params)\n",
    "    \n",
    "    # matrices to store draws and the fit\n",
    "    A_mat = np.zeros((draws,len(X)))\n",
    "    beta0_mat = np.zeros((draws,params[\"num_vars\"]**2*params[\"lags\"]))\n",
    "    beta1_mat = np.zeros((draws,params[\"num_vars\"]**2*params[\"lags\"]))\n",
    "    acceptrate = np.zeros((draws,1))\n",
    "    valJ = np.zeros((draws,1))\n",
    "    \n",
    "    # size of the draws for the MCMC procedures\n",
    "    sigmaMH = 0.0005*np.ones((X.shape))\n",
    "    \n",
    "    if s_prior[\"scale_penalty\"] == 0:\n",
    "        sigmaMH[-1] = 0.05\n",
    "    else: \n",
    "        sigmaMH[-1] = 0\n",
    "    \n",
    "    scaleSIGMA=1\n",
    "    n_periods = np.array(exog).shape[0]\n",
    "    \n",
    "    logL, beta0E, beta1E, beta_const, beta_other, omega_1E,omega_2E,theta,gamma,residsM = vec2matSF_struct(X,state,lagged_vars,y,exog,s_desc[\"T\"],params[\"c_case\"],params[\"lags\"],params[\"num_vars\"],n_periods)\n",
    "    \n",
    "    i = 1 \n",
    "    np.random.seed(5318008) #set seed\n",
    "    shocks0 = np.random.randn(X.shape[0],draws*5)\n",
    "    counterB = 1\n",
    "    counterX = 0\n",
    "    bar = progressbar.ProgressBar(max_value=draws) # initialize progressbar\n",
    "    \n",
    "    while i < draws:\n",
    "        A1 = X + sigmaMH * shocks0[:,counterB] # draw new stock to paramter value\n",
    "        counterB = counterB + 1\n",
    "        \n",
    "        omega_1_candidate, omega_2_candidate, theta_candidate = vec2matScov(A1)\n",
    "        \n",
    "        # check if eigenvalues of Omega0 and Omega1 are greater than zero\n",
    "        # if not, discard the candidate vector of parameters\n",
    "        \n",
    "        if np.min(eig(omega_1_candidate)[0])>0 and np.min(eig(omega_2_candidate)[0])>0:\n",
    "            n_periods = np.array(exog).shape[0]\n",
    "            J2 = max_LSTVAR_mleS_struct(A1,state,lagged_vars,y,exog,T,params)\n",
    "        \n",
    "        # stochastically accept/reject candidate values\n",
    "        v0 = np.exp(J1-J2) # compute the exp of ration of loss functions\n",
    "        v1 = min(v0,1) # determine accept probability\n",
    "        U = np.random.randn(1,1) #draw rv from uniform to decide whether accept\n",
    "        \n",
    "        if U < v1: #accept if the U is less than acceptance rate\n",
    "            X = A1\n",
    "            acceptrate[i] = 1\n",
    "            valJ[i] = J2\n",
    "            J1 = J2\n",
    "            logL, beta0E, beta1E, beta_const, beta_other, omega_1E,omega_2E,theta,gamma,residsM = vec2matSF_struct(X,state,lagged_vars,y,exog,s_desc[\"T\"],params[\"c_case\"],params[\"lags\"],params[\"num_vars\"],n_periods)\n",
    "        else:\n",
    "            acceptrate[i] = 0\n",
    "            valJ[i] = J1\n",
    "    \n",
    "    \n",
    "        A_mat[i] = X.T\n",
    "        beta_const_mat = []\n",
    "        beta_other_mat = []\n",
    "        \n",
    "        if params[\"lags\"]>0:\n",
    "            # adjust size of the shocks on the fly\n",
    "            beta0_mat[i,:] = beta0E.flatten(\"F\").T\n",
    "            beta1_mat[i,:] = beta1E.flatten(\"F\").T\n",
    "            \n",
    "            beta_other_mat.append(beta_other.flatten(\"F\").T)\n",
    "            beta_const_mat.append(beta_const.flatten(\"F\").T)\n",
    "        i+=1\n",
    "        bar.update(i)\n",
    "        counterX = 0\n",
    "        \n",
    "        # adjust size of the shocks on the fly\n",
    "        if i < 400000:\n",
    "            if i % 500 == 0:\n",
    "                if np.mean(acceptrate[max(1,i-500):i]) > 0.35:\n",
    "                    sigmaMH = 1.1 * sigmaMH\n",
    "                    scaleSIGMA = 1.1 * scaleSIGMA\n",
    "                elif np.mean(acceptrate[max(1,i-500):i]) > 0.25:\n",
    "                    sigmaMH = 0.9 * sigmaMH\n",
    "                    scaleSIGMA = 0.9 * scaleSIGMA\n",
    "        else:\n",
    "            counterX += 1\n",
    "        \n",
    "        if counterX > 200:#too many draws - Go back to previous successful draw\n",
    "            X = A_mat[i-1,:].T\n",
    "            J1 = valJ[i-1]\n",
    "            counterX = 0\n",
    "    \n",
    "    return A_mat, beta0_mat,beta1_mat, acceptrate,valJ,beta_const_mat, beta_other_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "unauthorized-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "draws = 100\n",
    "burn_in = int(draws*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "anonymous-update",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markov chain Monte Carlo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:12 ETA:  00:00:00"
     ]
    }
   ],
   "source": [
    "A_mat, beta0_mat,beta1_mat, acceptrate,valJ,beta_const_mat, beta_other_mat = obj_logLoptimizeMCMC_struct(param0_MCMC,draws,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "current-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean results\n",
    "A_mat = A_mat[burn_in:]\n",
    "post_length = A_mat.shape[0]\n",
    "beta0_mat = beta0_mat[burn_in:]\n",
    "beta1_mat = beta1_mat[burn_in:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "instant-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_1,omega_2,theta = vec2matScov(np.mean(A_mat.T,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "after-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cholesky\n",
    "s1 = cholesky(omega_1)\n",
    "s2 = cholesky(omega_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "different-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta0=unvec(np.mean(beta0_mat.T,axis=1),y.shape[1],y.shape[1]*params[\"lags\"])\n",
    "beta1=unvec(np.mean(beta1_mat.T,axis=1),y.shape[1],y.shape[1]*params[\"lags\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-attribute",
   "metadata": {},
   "source": [
    "# Identified impulse response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "verbal-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "IRF1 = np.ones((params[\"h\"],y.shape[1],post_length))*np.NaN\n",
    "IRF2 = np.ones((params[\"h\"],y.shape[1],post_length))*np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "toxic-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dyn_multipliers(A,c_case, params):\n",
    "    \n",
    "    p = params[\"lags\"]\n",
    "    h = params[\"h\"]\n",
    "    n = y.shape[1]\n",
    "\n",
    "    AR = A[0:].T\n",
    "\n",
    "    AR_3d = np.empty((n,n,p))\n",
    "\n",
    "    for lag in range(1,p+1):\n",
    "        AR_3d[:,:,lag-1] = AR[(lag-1)*n:lag*n]\n",
    "\n",
    "\n",
    "    C = np.empty((n,n,p+h))\n",
    "    C[:,:,p-1] = 0\n",
    "    C[:,:,p] = np.eye(n)\n",
    "\n",
    "    for t in range(p+2,p+h):\n",
    "        acc = 0\n",
    "        for j in range(1,p+1):\n",
    "            acc = acc + AR_3d[:,:,j-1]@C[:,:,t-j]\n",
    "        C[:,:,t] = acc\n",
    "\n",
    "    C = C[:,:,p:]\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "extended-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = unvec(beta0_mat[1],y.shape[1],y.shape[1]*params[\"lags\"])\n",
    "C1 = dyn_multipliers(A1,c_case,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "boolean-madagascar",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-0b13d11c44d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mIRF1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mC1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mshock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "shock = np.zeros(n)\n",
    "shock[params[\"shockposition\"]-1] = 1 \n",
    "\n",
    "for hh in range(h):\n",
    "    IRF1[hh,:,i] = (C1[:,:,hh]*s1@shock).reshape(-1,1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "IRF1[hh,:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "tribal-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(post_length):\n",
    "    om_1,om_2,theta_IRF = vec2matScov(A_mat[i])\n",
    "    \n",
    "    s1 = cholesky(om_1)\n",
    "    s2 = cholesky(om_2)\n",
    "    c_case = 0 #parameters for constant not included in A&G\n",
    "        \n",
    "    # Impulse response in state 1\n",
    "    A1 = unvec(beta0_mat[i],y.shape[1],y.shape[1]*params[\"lags\"])\n",
    "    C1 = dyn_multipliers(A1,c_case,params)\n",
    "    \n",
    "    shock = np.zeros(n)\n",
    "    shock[params[\"shockposition\"]-1] = 1 \n",
    "    \n",
    "    for hh in range(h):\n",
    "        IRF1[hh,:,i] = (C1[:,:,hh]*s1@shock).reshape(-1,1).T\n",
    "    \n",
    "    # Impulse response in state 2\n",
    "    \n",
    "    A2 = unvec(beta1_mat[i].T,y.shape[1],y.shape[1]*params[\"lags\"])\n",
    "    C2 = dyn_multipliers(A2,c_case,params)\n",
    "    \n",
    "    shock = np.zeros(n)\n",
    "    shock[params[\"shockposition\"]-1] = 1 \n",
    "    \n",
    "    for hh in range(h):\n",
    "        IRF2[hh,:,i] = (C2[:,:,hh]*s2@shock).reshape(-1,1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "alternate-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upper and lower thresholds\n",
    "CI_LO = (100-params[\"CI\"])/2\n",
    "CI_UP = 100-params[\"CI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "curious-envelope",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+000, 0.00000000e+000, 4.09417725e-001],\n",
       "       [0.00000000e+000,             nan, 1.25260763e+256],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan],\n",
       "       [            nan,             nan,             nan]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(IRF1,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-apollo",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-savage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-combine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-marshall",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-sunset",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-concentration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-logan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-embassy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-steps",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-miller",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-internet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-knock",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-monte",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-session",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-durham",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
